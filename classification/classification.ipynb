{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "# Afficher toutes les lignes du résultat\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STANDARDISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#print(df_train.dtypes)\n",
    "def standardize_dataframe(dataframe):\n",
    "    # Sélectionner uniquement les colonnes numériques\n",
    "    numeric_cols = dataframe.select_dtypes(include=['float64', 'int64','int32']).columns\n",
    "    \n",
    "    # Copier le DataFrame pour éviter de modifier l'original\n",
    "    standardized_df = dataframe.copy()\n",
    "    \n",
    "    # Standardiser les colonnes numériques\n",
    "    scaler = StandardScaler()\n",
    "    standardized_df[numeric_cols] = scaler.fit_transform(dataframe[numeric_cols])\n",
    "    \n",
    "    return standardized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximisation_marge(montant,status):\n",
    "    taux_marge = 0.05\n",
    "    if status == \"TP\":\n",
    "        res = 0 # le fraudeur est détecté\n",
    "    elif status == \"TN\":\n",
    "        res = taux_marge * montant # un client honnête est accepté\n",
    "    elif status == \"FP\":\n",
    "        res = 0.7*taux_marge * montant # un client honnête est bloqué     \n",
    "    elif status == \"FN\": # un fraudeur est accepté \n",
    "        if montant <= 20:\n",
    "            res = 0\n",
    "        elif montant <= 50:\n",
    "            res = -0.2 * montant\n",
    "        elif montant <= 100:\n",
    "            res = -0.3 * montant\n",
    "        elif montant <= 200:\n",
    "            res = -0.5 * montant\n",
    "        else:\n",
    "            res = -0.8 * montant\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALISATION - SCORER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(y_true, y_pred, montants):\n",
    "    total_marge = 0\n",
    "    inde = 0\n",
    "    for i in range(len(montants)):\n",
    "        status = \"\"\n",
    "        if y_true[inde] == 1 and y_pred[inde] == 1:\n",
    "            status = \"TP\"\n",
    "        elif y_true[inde] == 0 and y_pred[inde] == 0:\n",
    "            status = \"TN\"\n",
    "        elif y_true[inde] == 0 and y_pred[inde] == 1:\n",
    "            status = \"FP\"\n",
    "        elif y_true[inde] == 1 and y_pred[inde] == 0:\n",
    "            status = \"FN\" \n",
    "\n",
    "        total_marge += maximisation_marge(montants[inde], status)\n",
    "        inde += 1\n",
    "    \n",
    "    return total_marge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALISATION - CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "#Machine learning algorithms like linear regression, logistic regression, neural network, PCA (principal component analysis), etc., \n",
    "#that use gradient descent as an optimization technique require data to be scaled\n",
    "\n",
    "\n",
    "class_weights = {0: 1.0, 1: 20.0}\n",
    "\n",
    "models = {\n",
    "    'Random_Forest': RandomForestClassifier(), # LUI\n",
    "    'xgb_model': xgb.XGBClassifier(), # LUI\n",
    "    #'Gradient_Boosting': GradientBoostingClassifier(),\n",
    "    #'K_Nearest_Neighbors': KNeighborsClassifier(),\n",
    "    'Support_Vector_Machine': SVC(), # LUI\n",
    "    #'Neural_Network': MLPClassifier(),\n",
    "    'Linear_Discriminant_Analysis': LinearDiscriminantAnalysis() # LUI\n",
    "    #'Logistic_Regression': LogisticRegression()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'Random_Forest': {\n",
    "        'criterion': ['gini'],\n",
    "        'n_estimators': [5,100],\n",
    "        'max_depth': [None, 10],\n",
    "        'class_weight' : [None, class_weights],\n",
    "        'random_state': [42]\n",
    "        },\n",
    "    'xgb_model': {\n",
    "        'objective': ['binary:logistic'],\n",
    "        'n_estimators': [5,100],\n",
    "        #'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [None,3,10],\n",
    "        'subsample': [0.5,1.0],\n",
    "        #'colsample_bytree': [0.8, 1.0],\n",
    "        #'gamma': [0, 0.1, 0.2],\n",
    "        #'min_child_weight': [1, 5, 10],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    'Gradient_Boosting': {\n",
    "        #'n_estimators': [50, 100, 200],\n",
    "        #'learning_rate': [0.01, 0.1, 0.2],\n",
    "        #'max_depth': [3, 5, 7],\n",
    "        #'subsample': [0.8, 1.0],\n",
    "        #'min_samples_split': [2, 5, 10],\n",
    "        #'min_samples_leaf': [1, 2, 4],\n",
    "        #'max_features': [None, 'sqrt', 'log2'],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    'K_Nearest_Neighbors': {\n",
    "        'n_neighbors': [3,10],\n",
    "        #'weights': ['uniform', 'distance'],\n",
    "        #'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        #'leaf_size': [20, 30, 40],\n",
    "        #'p': [1, 2]\n",
    "    },\n",
    "    'Support_Vector_Machine': {\n",
    "        'C': [0.1, 1.0, 5.0],\n",
    "        'kernel': ['linear','rbf'],\n",
    "        #'degree': [2, 3, 4],\n",
    "        #'gamma': ['scale', 'auto'],\n",
    "        'class_weight': [None,class_weights],\n",
    "        'random_state': [42]    \n",
    "       },\n",
    "   'Neural_Network': {\n",
    "        #'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "        #'activation': ['relu', 'tanh', 'logistic'],\n",
    "        #'solver': ['sgd', 'adam'],\n",
    "        #'alpha': [0.0001, 0.001, 0.01],\n",
    "        #'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "        #'max_iter': [100, 200, 300],\n",
    "        #'early_stopping': [True, False],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    'Linear_Discriminant_Analysis': {\n",
    "        'solver': ['svd', 'lsqr'],\n",
    "        'shrinkage': [None, 'auto']\n",
    "        #'n_components': [None, 1, 2, 3]\n",
    "    },\n",
    "     'Logistic_Regression': {\n",
    "        #'penalty': ['l1', 'l2'],\n",
    "        #'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        #'fit_intercept': [True, False],\n",
    "        #'class_weight': [None, 'balanced'],\n",
    "        #'solver': ['liblinear', 'saga'],\n",
    "        #'max_iter': [100, 200, 300],\n",
    "        'class_weight' : [None, class_weights],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"simple\",\"undersampling\",\"smote\"]\n",
    "percents = [\"1\",\"3\",\"5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINNING : GRID SEARCH - OPTIMISATION F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Random_Forest for method simple\n",
      "\n",
      "Training Random_Forest for method simple and 5 % of frauds\n",
      "{'criterion': ['gini'], 'n_estimators': [5, 100], 'max_depth': [None, 10], 'class_weight': [None, {0: 1.0, 1: 20.0}], 'random_state': [42]}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nagrimault\\Documents\\fac\\s1\\fouille_donnees\\Cheques-Fraud-Detection\\classification\\classification.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, scoring\u001b[39m=\u001b[39mf1_scorer, cv\u001b[39m=\u001b[39mtscv, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Effectuer la recherche de grille\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Afficher les résultats\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X14sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m     Best parameters for \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m, grid_search\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pickle\n",
    "\n",
    "\n",
    "for m in methods:\n",
    "    if m == \"simple\":\n",
    "        df_train = pd.read_csv(\"../data/\"+m+\"/dataframe_train.csv\")\n",
    "        df_train = df_train.sort_values(by=\"Heure\")\n",
    "        for model_name, model in models.items():\n",
    "                print(f\"\\n Training {model_name} for method {m}\")\n",
    "\n",
    "                X_train = df_train.drop(columns=[\"FlagImpaye\",\"CodeDecision\"])\n",
    "                X_train = standardize_dataframe(X_train) # on standardise les données\n",
    "                y_train = df_train[\"FlagImpaye\"]\n",
    "\n",
    "                # Boucle sur chaque modèle\n",
    "                for model_name, model in models.items():\n",
    "                    print(f\"\\nTraining {model_name} for method {m} and {p} % of frauds\")\n",
    "\n",
    "                    # Définir les paramètres que vous souhaitez tester dans la recherche de grille\n",
    "                    param_grid = param_grids[model_name]\n",
    "                    print(param_grid)\n",
    "\n",
    "                    f1_scorer = make_scorer(f1_score,greater_is_better=True)\n",
    "\n",
    "                    # Utiliser TimeSeriesSplit pour la validation croisée\n",
    "                    tscv = TimeSeriesSplit(n_splits=4)\n",
    "                    \n",
    "                    # Créer la grille de recherche avec votre fonction personnalisée comme mesure d'évaluation\n",
    "                    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=f1_scorer, cv=tscv, n_jobs=-1)\n",
    "\n",
    "                    # Effectuer la recherche de grille\n",
    "                    grid_search.fit(X_train, y_train)\n",
    "\n",
    "                    \n",
    "                    # Afficher les résultats\n",
    "                    print(f\"\\n     Best parameters for {model_name}: \", grid_search.best_params_)\n",
    "                    print(f\"     Meilleur f1 score pour {model_name}: \", grid_search.best_score_)\n",
    "\n",
    "                    # Sauvegarder le meilleur modèle si nécessaire\n",
    "                    best_model = grid_search.best_estimator_\n",
    "                    filename = '../models/'+m+\"/\"+p+\"/\"+ model_name + '.pkl'\n",
    "                    pickle.dump(best_model, open(filename, \"wb\"))\n",
    "    else:\n",
    "        for p in percents:\n",
    "            df_train = pd.read_csv(\"../data/\"+m+\"/dataframe_train_\"+p+\"_percent.csv\")\n",
    "            df_train = df_train.sort_values(by=\"Heure\")\n",
    "        \n",
    "            X_train = df_train.drop(columns=[\"FlagImpaye\",\"CodeDecision\"])\n",
    "\n",
    "            X_train = standardize_dataframe(X_train) # on standardise les données\n",
    "            y_train = df_train[\"FlagImpaye\"]\n",
    "\n",
    "            # Boucle sur chaque modèle\n",
    "            for model_name, model in models.items():\n",
    "                print(f\"\\nTraining {model_name} for method {m} and {p} % of frauds\")\n",
    "\n",
    "                # Définir les paramètres que vous souhaitez tester dans la recherche de grille\n",
    "                param_grid = param_grids[model_name]\n",
    "                print(param_grid)\n",
    "\n",
    "                f1_scorer = make_scorer(f1_score,greater_is_better=True)\n",
    "\n",
    "                # Utiliser TimeSeriesSplit pour la validation croisée\n",
    "                tscv = TimeSeriesSplit(n_splits=4)\n",
    "                \n",
    "                \n",
    "                # Créer la grille de recherche avec votre fonction personnalisée comme mesure d'évaluation\n",
    "                grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=f1_scorer, cv=tscv, n_jobs=-1)\n",
    "\n",
    "                # Effectuer la recherche de grille\n",
    "                grid_search.fit(X_train, y_train)\n",
    "\n",
    "                \n",
    "                # Afficher les résultats\n",
    "                print(f\"\\n     Best parameters for {model_name}: \", grid_search.best_params_)\n",
    "                print(f\"     Meilleur f1 score pour {model_name}: \", grid_search.best_score_)\n",
    "\n",
    "                # Sauvegarder le meilleur modèle si nécessaire\n",
    "                best_model = grid_search.best_estimator_\n",
    "                filename = '../models/'+m+\"/\"+p+\"/\"+ model_name + '.pkl'\n",
    "                pickle.dump(best_model, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH MARGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random_Forest for method simple\n",
      "{'criterion': 'gini', 'n_estimators': 5, 'max_depth': None, 'class_weight': None, 'random_state': 42}\n",
      "  marge :  3534046.966351799\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nagrimault\\Documents\\fac\\s1\\fouille_donnees\\Cheques-Fraud-Detection\\classification\\classification.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X16sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m X_val_fold \u001b[39m=\u001b[39m standardize_dataframe(X_val_fold) \u001b[39m# on standardise les données*\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X16sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# Entraîner le modèle\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X16sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train_fold, y_train_fold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X16sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Prédire sur l'ensemble de validation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nagrimault/Documents/fac/s1/fouille_donnees/Cheques-Fraud-Detection/classification/classification.ipynb#X16sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m y_val_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_val_fold)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pickle\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Classifiers (UnderSampling):\n",
    "# Logistic Regression classifier is more accurate than the other three classifiers in most cases. (We will further analyze Logistic Regression)\n",
    "# GridSearchCV is used to determine the paremeters that gives the best predictive score for the classifiers.\n",
    "# Logistic Regression has the best Receiving Operating Characteristic score (ROC), meaning that LogisticRegression pretty accurately separates fraud and non-fraud transactions.\n",
    "\n",
    "\n",
    "\n",
    "for m in methods:\n",
    "    if m == \"simple\":\n",
    "        df_train = pd.read_csv(\"../data/\"+m+\"/dataframe_train.csv\")\n",
    "        for model_name, model in models.items():\n",
    "                print(f\"\\nTraining {model_name} for method {m}\")\n",
    "\n",
    "                # Définir les paramètres que vous souhaitez tester dans la recherche de grille\n",
    "                param_grid = param_grids[model_name]\n",
    "\n",
    "                # Initialiser les variables pour stocker les meilleurs paramètres et le meilleur score\n",
    "                best_params = None\n",
    "                best_score = 0\n",
    "\n",
    "                # Effectuer une recherche par grille manuelle\n",
    "                for params in product(*param_grid.values()):\n",
    "                    param_dict = dict(zip(param_grid.keys(), params))\n",
    "                    print(param_dict)\n",
    "\n",
    "                    # Initialiser le modèle avec les paramètres actuels\n",
    "                    clf = model.set_params(**param_dict)\n",
    "\n",
    "                    # Effectuer une validation croisée avec TimeSeriesSplit\n",
    "                    tscv = TimeSeriesSplit(n_splits=4)\n",
    "                    scores = []\n",
    "                    \n",
    "                    df_train_sorted = df_train.sort_values(by=\"Heure\")\n",
    "\n",
    "                    X_train = df_train_sorted.drop(columns=[\"FlagImpaye\",\"CodeDecision\"])\n",
    "                    y_train = df_train_sorted[\"FlagImpaye\"]\n",
    "                    \n",
    "                    for train_index, val_index in tscv.split(X_train):\n",
    "                        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "                        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "                        # train :\n",
    "                        X_train_fold = standardize_dataframe(X_train_fold) # on standardise les données*\n",
    "                        \n",
    "                        #test :\n",
    "                        montants = X_val_fold[\"Montant\"]\n",
    "                        montants = montants.values\n",
    "                        X_val_fold = standardize_dataframe(X_val_fold) # on standardise les données*\n",
    "\n",
    "                        # Entraîner le modèle\n",
    "                        clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "                        # Prédire sur l'ensemble de validation\n",
    "                        y_val_pred = clf.predict(X_val_fold)\n",
    "\n",
    "                        y_val_fold = y_val_fold.values\n",
    "                        y_val_pred = y_val_pred.tolist()     \n",
    "                        y_val_fold = y_val_fold.tolist()\n",
    "                        montants = montants.tolist()\n",
    "\n",
    "                        \n",
    "                        score_marge = custom_score(y_val_fold, y_val_pred,montants)        \n",
    "                        print(\"  marge : \",score_marge)\n",
    "                        scores.append(score_marge)\n",
    "                    \n",
    "                    # Calculer le score moyen sur les plis\n",
    "                    avg_score = np.mean(scores)\n",
    "                    print(\"   moyenne : \",avg_score)\n",
    "\n",
    "                    if avg_score > best_score:\n",
    "                        best_score = avg_score\n",
    "                        best_params = param_dict\n",
    "                        best_model = clf\n",
    "\n",
    "\n",
    "                # Afficher les résultats\n",
    "                print(f\"\\n     Best parameters pour {model_name}: {best_params}\")\n",
    "                #print(f\"     Best marge pour {model_name}: {best_score}\")\n",
    "\n",
    "                # Sauvegarder le meilleur modèle\n",
    "                filename = '../models/'+m+\"/\"+ model_name + '.pkl'\n",
    "                pickle.dump(best_model, open(filename, \"wb\"))\n",
    "    else:\n",
    "        for p in percents:\n",
    "            df_train = pd.read_csv(\"../data/\"+m+\"/dataframe_train_\"+p+\"_percent.csv\")\n",
    "\n",
    "            # Boucle sur chaque modèle\n",
    "            for model_name, model in models.items():\n",
    "                print(f\"\\nTraining {model_name} for method {m} and {p} % of frauds\")\n",
    "\n",
    "                # Définir les paramètres que vous souhaitez tester dans la recherche de grille\n",
    "                param_grid = param_grids[model_name]\n",
    "\n",
    "                # Initialiser les variables pour stocker les meilleurs paramètres et le meilleur score\n",
    "                best_params = None\n",
    "                best_score = 0\n",
    "\n",
    "                # Effectuer une recherche par grille manuelle\n",
    "                for params in product(*param_grid.values()):\n",
    "                    param_dict = dict(zip(param_grid.keys(), params))\n",
    "                    print(param_dict)\n",
    "\n",
    "                    # Initialiser le modèle avec les paramètres actuels\n",
    "                    clf = model.set_params(**param_dict)\n",
    "\n",
    "                    # Effectuer une validation croisée avec TimeSeriesSplit\n",
    "                    tscv = TimeSeriesSplit(n_splits=4)\n",
    "                    scores = []\n",
    "                    \n",
    "                    df_train_sorted = df_train.sort_values(by=\"Heure\")\n",
    "\n",
    "                    X_train = df_train_sorted.drop(columns=[\"FlagImpaye\",\"CodeDecision\"])\n",
    "                    y_train = df_train_sorted[\"FlagImpaye\"]\n",
    "                    \n",
    "                    for train_index, val_index in tscv.split(X_train):\n",
    "                        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "                        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "                        # train :\n",
    "                        X_train_fold = standardize_dataframe(X_train_fold) # on standardise les données*\n",
    "                        \n",
    "                        #test :\n",
    "                        montants = X_val_fold[\"Montant\"]\n",
    "                        montants = montants.values\n",
    "                        X_val_fold = standardize_dataframe(X_val_fold) # on standardise les données*\n",
    "\n",
    "                        # Entraîner le modèle\n",
    "                        clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "                        # Prédire sur l'ensemble de validation\n",
    "                        y_val_pred = clf.predict(X_val_fold)\n",
    "\n",
    "                        y_val_fold = y_val_fold.values\n",
    "                        y_val_pred = y_val_pred.tolist()     \n",
    "                        y_val_fold = y_val_fold.tolist()\n",
    "                        montants = montants.tolist()\n",
    "\n",
    "                        \n",
    "                        score_marge = custom_score(y_val_fold, y_val_pred,montants)        \n",
    "                        print(\"  marge : \",score_marge)\n",
    "                        scores.append(score_marge)\n",
    "                    \n",
    "                    # Calculer le score moyen sur les plis\n",
    "                    avg_score = np.mean(scores)\n",
    "                    print(\"   moyenne : \",avg_score)\n",
    "\n",
    "                    if avg_score > best_score:\n",
    "                        best_score = avg_score\n",
    "                        best_params = param_dict\n",
    "                        best_model = clf\n",
    "\n",
    "\n",
    "                # Afficher les résultats\n",
    "                print(f\"\\n     Best parameters pour {model_name}: {best_params}\")\n",
    "                #print(f\"     Best marge pour {model_name}: {best_score}\")\n",
    "\n",
    "                # Sauvegarder le meilleur modèle\n",
    "                filename = '../models/'+m+\"/\"+p+\"/\"+ model_name + '.pkl'\n",
    "                pickle.dump(best_model, open(filename, \"wb\"))\n",
    "\n",
    "# Prendre le meilleur modèle et tuner ses paramètres à fond !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'simple': {'1': None, '3': None, '5': {}, 'Random_Forest': RandomForestClassifier(max_depth=3, n_estimators=3, random_state=42), 'xgb_model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=3, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)}, 'undersampling': {'1': {'Random_Forest': RandomForestClassifier(max_depth=3, n_estimators=3, random_state=42), 'xgb_model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=3, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)}, '3': {'Random_Forest': RandomForestClassifier(max_depth=3, n_estimators=3, random_state=42), 'xgb_model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=3, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)}, '5': {'Random_Forest': RandomForestClassifier(max_depth=3, n_estimators=3, random_state=42), 'xgb_model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=3, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)}}, 'smote': {'1': {'Random_Forest': RandomForestClassifier(max_depth=3, n_estimators=3, random_state=42), 'xgb_model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=3, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)}, '3': {'Random_Forest': RandomForestClassifier(max_depth=3, n_estimators=3, random_state=42), 'xgb_model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=3, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)}, '5': {'Random_Forest': RandomForestClassifier(max_depth=3, n_estimators=3, random_state=42), 'xgb_model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=3, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "methods = [\"simple\",\"undersampling\",\"smote\"]\n",
    "percents = [\"1\",\"3\",\"5\"]\n",
    "\n",
    "\n",
    "loaded_models = {method: {percent: None for percent in percents} for method in methods}\n",
    "\n",
    "for m in methods:\n",
    "    if m == \"simple\":\n",
    "        loaded_models[m][p] = {}\n",
    "        for model_name in models.keys():\n",
    "            filename = '../models/'+m+\"/\"+ model_name + '.pkl'\n",
    "            with open(filename, 'rb') as file:\n",
    "                loaded_models[m][model_name] = pickle.load(file)\n",
    "    else:\n",
    "        for p in percents:\n",
    "            loaded_models[m][p] = {}\n",
    "            for model_name in models.keys():\n",
    "                filename = '../models/'+m+\"/\"+p+\"/\"+ model_name + '.pkl'\n",
    "                with open(filename, 'rb') as file:\n",
    "                    loaded_models[m][p][model_name] = pickle.load(file)\n",
    "\n",
    "\n",
    "# loaded_models_f1 = {method: {percent: None for percent in percents} for method in methods}\n",
    "\n",
    "# for m in methods:\n",
    "#     for p in percents:\n",
    "#         loaded_models[m][p] = {}\n",
    "#         for model_name in models.keys():\n",
    "#             filename = '../models/'+m+\"/\"+p+\"/\"+ model_name + '.pkl'\n",
    "#             with open(filename, 'rb') as file:\n",
    "#                 loaded_models[m][p][model_name] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTING WITH BEST MARGE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #### Testing Random_Forest for method simple ####\n",
      "\n",
      "     F1 score de  Random_Forest  sur l'ensemble de test : 0.003938200545289306\n",
      "     Marge de  Random_Forest  sur l'ensemble de test : 1944881.13\n",
      "     Montant gagné avec le modèle : 3029.439999999944\n",
      "\n",
      " #### Testing xgb_model for method simple ####\n",
      "\n",
      "     F1 score de  xgb_model  sur l'ensemble de test : 0.026839119259969915\n",
      "     Marge de  xgb_model  sur l'ensemble de test : 1946809.03\n",
      "     Montant gagné avec le modèle : 4957.340000000084\n",
      "\n",
      " #### Testing Random_Forest for method undersampling and 1 % of frauds ####\n",
      "\n",
      "     F1 score de  Random_Forest  sur l'ensemble de test : 0.02183967112024666\n",
      "     Marge de  Random_Forest  sur l'ensemble de test : 1954908.58\n",
      "     Montant gagné avec le modèle : 13056.89000000013\n",
      "\n",
      " #### Testing xgb_model for method undersampling and 1 % of frauds ####\n",
      "\n",
      "     F1 score de  xgb_model  sur l'ensemble de test : 0.029808374733853792\n",
      "     Marge de  xgb_model  sur l'ensemble de test : 1968845.38\n",
      "     Montant gagné avec le modèle : 26993.689999999944\n",
      "\n",
      " #### Testing Random_Forest for method undersampling and 3 % of frauds ####\n",
      "\n",
      "     F1 score de  Random_Forest  sur l'ensemble de test : 0.02843950175756611\n",
      "     Marge de  Random_Forest  sur l'ensemble de test : 1961868.06\n",
      "     Montant gagné avec le modèle : 20016.37000000011\n",
      "\n",
      " #### Testing xgb_model for method undersampling and 3 % of frauds ####\n",
      "\n",
      "     F1 score de  xgb_model  sur l'ensemble de test : 0.07917645433190547\n",
      "     Marge de  xgb_model  sur l'ensemble de test : 2046338.05\n",
      "     Montant gagné avec le modèle : 104486.3600000001\n",
      "\n",
      " #### Testing Random_Forest for method undersampling and 5 % of frauds ####\n",
      "\n",
      "     F1 score de  Random_Forest  sur l'ensemble de test : 0.027379325581585647\n",
      "     Marge de  Random_Forest  sur l'ensemble de test : 1958502.65\n",
      "     Montant gagné avec le modèle : 16650.959999999963\n",
      "\n",
      " #### Testing xgb_model for method undersampling and 5 % of frauds ####\n",
      "\n",
      "     F1 score de  xgb_model  sur l'ensemble de test : 0.03852506861734497\n",
      "     Marge de  xgb_model  sur l'ensemble de test : 2025025.42\n",
      "     Montant gagné avec le modèle : 83173.72999999998\n",
      "\n",
      " #### Testing Random_Forest for method smote and 1 % of frauds ####\n",
      "\n",
      "     F1 score de  Random_Forest  sur l'ensemble de test : 0.0030358227079538558\n",
      "     Marge de  Random_Forest  sur l'ensemble de test : 1942056.2\n",
      "     Montant gagné avec le modèle : 204.5100000000093\n",
      "\n",
      " #### Testing xgb_model for method smote and 1 % of frauds ####\n",
      "\n",
      "     F1 score de  xgb_model  sur l'ensemble de test : 0.020568688483216958\n",
      "     Marge de  xgb_model  sur l'ensemble de test : 1878086.19\n",
      "     Montant gagné avec le modèle : -63765.5\n",
      "\n",
      " #### Testing Random_Forest for method smote and 3 % of frauds ####\n",
      "\n",
      "     F1 score de  Random_Forest  sur l'ensemble de test : 0.006263048016701462\n",
      "     Marge de  Random_Forest  sur l'ensemble de test : 1945739.11\n",
      "     Montant gagné avec le modèle : 3887.4200000001583\n",
      "\n",
      " #### Testing xgb_model for method smote and 3 % of frauds ####\n",
      "\n",
      "     F1 score de  xgb_model  sur l'ensemble de test : 0.018605321987452222\n",
      "     Marge de  xgb_model  sur l'ensemble de test : 1870332.09\n",
      "     Montant gagné avec le modèle : -71519.59999999986\n",
      "\n",
      " #### Testing Random_Forest for method smote and 5 % of frauds ####\n",
      "\n",
      "     F1 score de  Random_Forest  sur l'ensemble de test : 0.003938200545289306\n",
      "     Marge de  Random_Forest  sur l'ensemble de test : 1944881.13\n",
      "     Montant gagné avec le modèle : 3029.439999999944\n",
      "\n",
      " #### Testing xgb_model for method smote and 5 % of frauds ####\n",
      "\n",
      "     F1 score de  xgb_model  sur l'ensemble de test : 0.026839119259969915\n",
      "     Marge de  xgb_model  sur l'ensemble de test : 1946809.03\n",
      "     Montant gagné avec le modèle : 4957.340000000084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "index_modified = []\n",
    "for m in methods:\n",
    "    if m == \"simple\":\n",
    "        index_modified.append(m)\n",
    "    else:\n",
    "        for p in percents:\n",
    "            index_modified.append(m+\"_\"+p)\n",
    "  \n",
    "\n",
    "f1_df = pd.DataFrame(index=index_modified, columns=models.keys())\n",
    "marge_df = pd.DataFrame(index=index_modified, columns=models.keys())\n",
    "\n",
    "\n",
    "for m in methods:\n",
    "    if m == \"simple\":\n",
    "        df_test = pd.read_csv(\"../data/\"+m+\"/dataframe_test.csv\")\n",
    "        X_test = df_test.drop(columns=[\"FlagImpaye\",\"CodeDecision\"])\n",
    "        montants = X_test[\"Montant\"]\n",
    "        montants = montants.values\n",
    "        montants = montants.tolist()\n",
    "\n",
    "        X_test = standardize_dataframe(X_test) # on standardise les données   \n",
    "        \n",
    "        y_test = df_test[\"FlagImpaye\"]\n",
    "        y_test = y_test.values\n",
    "        y_test = y_test.tolist()\n",
    "\n",
    "        for model_name, model in model_dic.items():\n",
    "            print(f\"\\n #### Testing {model_name} for method {m} ####\")\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred = y_pred.tolist()\n",
    "\n",
    "            nom_ligne = m\n",
    "\n",
    "            # f1 score\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            f1_df.loc[nom_ligne, model_name] = f1\n",
    "\n",
    "            # marge\n",
    "            score_marge = custom_score(y_test, y_pred,montants)   \n",
    "            score_marge = round(score_marge,2)\n",
    "            marge_df.loc[nom_ligne, model_name] = score_marge\n",
    "\n",
    "\n",
    "            #marge_parfaite = round(custom_score(y_test, y_test,montants),2)\n",
    "            marge_laisse_passer_tout_le_monde = round(custom_score(y_test,[0]*len(y_test),montants),2)\n",
    "            marge_df.at[nom_ligne ,\"!_Montant_Gagné_!\"] = score_marge - marge_laisse_passer_tout_le_monde\n",
    "            #marge_df.at[nom_ligne ,\"!_Modele_Parfait_!\"] = marge_parfaite\n",
    "\n",
    "            # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            # disp = ConfusionMatrixDisplay(conf_matrix, display_labels=[False, True])\n",
    "            # disp.plot()\n",
    "            # plt.show()\n",
    "\n",
    "            print(\"\\n     F1 score de \",model_name,\" sur l'ensemble de test :\", f1)\n",
    "            print(\"     Marge de \",model_name,\" sur l'ensemble de test :\", score_marge)\n",
    "            #print(\"     Marge du modèle PARFAIT sur l'ensemble de test :\", marge_parfaite)\n",
    "            #rint(\"     Marge du modèle qui laisse passer tout le monde sur l'ensemble de test :\", marge_laisse_passer_tout_le_monde)\n",
    "            print(\"     Montant gagné avec le modèle :\", score_marge - marge_laisse_passer_tout_le_monde)\n",
    "            \n",
    "    else:\n",
    "        df_test = pd.read_csv(\"../data/\"+m+\"/dataframe_test.csv\")\n",
    "        X_test = df_test.drop(columns=[\"FlagImpaye\",\"CodeDecision\"])\n",
    "        montants = X_test[\"Montant\"]\n",
    "        montants = montants.values\n",
    "        montants = montants.tolist()\n",
    "\n",
    "        X_test = standardize_dataframe(X_test) # on standardise les données   \n",
    "        \n",
    "        y_test = df_test[\"FlagImpaye\"]\n",
    "        y_test = y_test.values\n",
    "        y_test = y_test.tolist()\n",
    "\n",
    "\n",
    "        for p, model_dic in loaded_models.get(m, {}).items():\n",
    "            for model_name, model in model_dic.items():\n",
    "                print(f\"\\n #### Testing {model_name} for method {m} and {p} % of frauds ####\")\n",
    "\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_pred = y_pred.tolist()\n",
    "\n",
    "                nom_ligne = m+\"_\"+p\n",
    "\n",
    "                # f1 score\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                f1_df.loc[nom_ligne, model_name] = f1\n",
    "\n",
    "                # marge\n",
    "                score_marge = custom_score(y_test, y_pred,montants)   \n",
    "                score_marge = round(score_marge,2)\n",
    "                marge_df.loc[nom_ligne, model_name] = score_marge\n",
    "    \n",
    "                #marge_parfaite = round(custom_score(y_test, y_test,montants),2)\n",
    "                marge_laisse_passer_tout_le_monde = round(custom_score(y_test,[0]*len(y_test),montants),2)\n",
    "                marge_df.at[nom_ligne ,\"!_Montant_Gagné_!\"] = score_marge - marge_laisse_passer_tout_le_monde\n",
    "                #marge_df.at[nom_ligne ,\"!_Modele_Parfait_!\"] = marge_parfaite\n",
    "\n",
    "                # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                # disp = ConfusionMatrixDisplay(conf_matrix, display_labels=[False, True])\n",
    "                # disp.plot()\n",
    "                # plt.show()\n",
    "\n",
    "                print(\"\\n     F1 score de \",model_name,\" sur l'ensemble de test :\", f1)\n",
    "                print(\"     Marge de \",model_name,\" sur l'ensemble de test :\", score_marge)\n",
    "                #print(\"     Marge du modèle PARFAIT sur l'ensemble de test :\", marge_parfaite)\n",
    "                #rint(\"     Marge du modèle qui laisse passer tout le monde sur l'ensemble de test :\", marge_laisse_passer_tout_le_monde)\n",
    "                print(\"     Montant gagné avec le modèle :\", score_marge - marge_laisse_passer_tout_le_monde)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marge Parfait :  2294459.36\n",
      "Marge tous honnete :  1941851.69\n"
     ]
    }
   ],
   "source": [
    "marge_parfaite = round(custom_score(y_test, y_test,montants),2)\n",
    "marge_laisse_passer_tout_le_monde = round(custom_score(y_test,[0]*len(y_test),montants),2)\n",
    "\n",
    "print(\"Marge Parfait : \",marge_parfaite)\n",
    "print(\"Marge tous honnete : \",marge_laisse_passer_tout_le_monde)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_Forest</th>\n",
       "      <th>xgb_model</th>\n",
       "      <th>!_Montant_Gagné_!</th>\n",
       "      <th>!_Modele_Parfait_!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>1944881.13</td>\n",
       "      <td>1946809.03</td>\n",
       "      <td>4957.34</td>\n",
       "      <td>2294459.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling_1</th>\n",
       "      <td>1954908.58</td>\n",
       "      <td>1968845.38</td>\n",
       "      <td>26993.69</td>\n",
       "      <td>2294459.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling_3</th>\n",
       "      <td>1961868.06</td>\n",
       "      <td>2046338.05</td>\n",
       "      <td>104486.36</td>\n",
       "      <td>2294459.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling_5</th>\n",
       "      <td>1958502.65</td>\n",
       "      <td>2025025.42</td>\n",
       "      <td>83173.73</td>\n",
       "      <td>2294459.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smote_1</th>\n",
       "      <td>1942056.2</td>\n",
       "      <td>1878086.19</td>\n",
       "      <td>-63765.50</td>\n",
       "      <td>2294459.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smote_3</th>\n",
       "      <td>1945739.11</td>\n",
       "      <td>1870332.09</td>\n",
       "      <td>-71519.60</td>\n",
       "      <td>2294459.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smote_5</th>\n",
       "      <td>1944881.13</td>\n",
       "      <td>1946809.03</td>\n",
       "      <td>4957.34</td>\n",
       "      <td>2294459.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random_Forest   xgb_model  !_Montant_Gagné_!  \\\n",
       "simple             1944881.13  1946809.03            4957.34   \n",
       "undersampling_1    1954908.58  1968845.38           26993.69   \n",
       "undersampling_3    1961868.06  2046338.05          104486.36   \n",
       "undersampling_5    1958502.65  2025025.42           83173.73   \n",
       "smote_1             1942056.2  1878086.19          -63765.50   \n",
       "smote_3            1945739.11  1870332.09          -71519.60   \n",
       "smote_5            1944881.13  1946809.03            4957.34   \n",
       "\n",
       "                 !_Modele_Parfait_!  \n",
       "simple                   2294459.36  \n",
       "undersampling_1          2294459.36  \n",
       "undersampling_3          2294459.36  \n",
       "undersampling_5          2294459.36  \n",
       "smote_1                  2294459.36  \n",
       "smote_3                  2294459.36  \n",
       "smote_5                  2294459.36  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marge_df.to_csv('../data/marge.csv')\n",
    "marge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_Forest</th>\n",
       "      <th>xgb_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.026839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling_1</th>\n",
       "      <td>0.02184</td>\n",
       "      <td>0.029808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling_3</th>\n",
       "      <td>0.02844</td>\n",
       "      <td>0.079176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling_5</th>\n",
       "      <td>0.027379</td>\n",
       "      <td>0.038525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smote_1</th>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.020569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smote_3</th>\n",
       "      <td>0.006263</td>\n",
       "      <td>0.018605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smote_5</th>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.026839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random_Forest xgb_model\n",
       "simple               0.003938  0.026839\n",
       "undersampling_1       0.02184  0.029808\n",
       "undersampling_3       0.02844  0.079176\n",
       "undersampling_5      0.027379  0.038525\n",
       "smote_1              0.003036  0.020569\n",
       "smote_3              0.006263  0.018605\n",
       "smote_5              0.003938  0.026839"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df.to_csv('../data/f1_score.csv')\n",
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimisation de la marge\n",
    "#  donner la marge maximale (si modèle hypothétiquement parfait) et comparer avec la meilleure marge obtenue, du genre 'on a perdu 10% de marge par rapport au modèle parfait'\n",
    "\n",
    "# faire ligne SMOTE 40% et 60% et comparer les résultats etc...\n",
    "# faire ligne UNDERSAMPLING 40% et 60% et comparer les résultats etc...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
